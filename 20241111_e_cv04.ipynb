{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01\n",
    "img = cv2.imread(\"img/Sailboat2.jpg\")\n",
    "mask = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(mask, 220, 255, cv2.THRESH_BINARY)\n",
    "dst = cv2.inpaint(img, mask, 1, cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Inpaint\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02\n",
    "img1 = cv2.imread(\"img/Pepper.bmp\", 0)\n",
    "h1, w1 = img1.shape\n",
    "center = (int(w1/2), int(h1/2))\n",
    "trans = cv2.getRotationMatrix2D(center, 30.0, 1.0)\n",
    "img2 = cv2.warpAffine(img1, trans, (w1, h1))\n",
    "h2, w2 = img2.shape\n",
    "detertor = cv2.ORB_create()\n",
    "kpts1, desc1 = detertor.detectAndCompute(img1, None)\n",
    "kpts2, desc2 = detertor.detectAndCompute(img2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc1)\n",
    "dst1 = np.zeros((h1, w1+w1, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img1, kpts1, matches, dst1)\n",
    "cv2.imshow(\"Matches\", dst1)\n",
    "\n",
    "matches = matcher.match(desc1, desc2)\n",
    "dst2 = np.zeros((max(h1, h2), w1+w2, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img2, kpts2, matches, dst2)\n",
    "cv2.imshow(\"Matches\", dst2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 画像を読み込む\n",
    "img1 = cv2.imread(\"img/mouse02.jpg\", 0)\n",
    "\n",
    "# 縮小するサイズを指定（幅と高さを半分にする例）\n",
    "width = int(img1.shape[1] * 0.1)\n",
    "height = int(img1.shape[0] * 0.1)\n",
    "dim = (width, height)\n",
    "\n",
    "# 画像を縮小\n",
    "resized_img = cv2.resize(img1, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# 縮小した画像を表示\n",
    "cv2.imshow(\"Resized Image\", resized_img)\n",
    "cv2.imwrite(\"img/mouse02_resized.jpg\", resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03\n",
    "img1 = cv2.imread(\"img/mouse01_resized.jpg\")\n",
    "h1, w1, _ = img1.shape\n",
    "center = (int(w1/2), int(h1/2))\n",
    "trans = cv2.getRotationMatrix2D(center, 30.0, 1.0)\n",
    "img2 = cv2.imread(\"img/mouse02_resized.jpg\")\n",
    "h2, w2, _ = img2.shape\n",
    "detertor = cv2.AKAZE_create()\n",
    "kpts1, desc1 = detertor.detectAndCompute(img1, None)\n",
    "kpts2, desc2 = detertor.detectAndCompute(img2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc1)\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "matches = matches[:10]\n",
    "dst1 = np.zeros((h1, w1+w1, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img1, kpts1, matches, dst1)\n",
    "cv2.imshow(\"Matches\", dst1)\n",
    "\n",
    "matches = matcher.match(desc1, desc2)\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "matches = matches[:10]\n",
    "dst2 = np.zeros((max(h1, h2), w1+w2, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img2, kpts2, matches, dst2)\n",
    "cv2.imshow(\"Matches\", dst2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 04\n",
    "img = cv2.imread(\"img/output.png\")\n",
    "cv2.imwrite(\"img/output_tmp.jpg\", img[100:200, 100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04\n",
    "img = cv2.imread(\"img/output.png\")\n",
    "tmp = cv2.imread(\"img/output_tmp.jpg\")\n",
    "h, w, _ = tmp.shape\n",
    "res = cv2.matchTemplate(img, tmp, cv2.TM_SQDIFF)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "top_left = min_loc \n",
    "bottom_right = (top_left[0]+w, top_left[1]+h)\n",
    "cv2.rectangle(img, top_left, bottom_right, 255, 2)\n",
    "cv2.imshow(\"Match\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 bell_pepper 0.99, cucumber 0.00, banana 0.00, Granny_Smith 0.00, butternut_squash 0.00, 9.0ms\n",
      "Speed: 2.4ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# 05\n",
    "model = YOLO(\"cascade/yolov8n-cls.pt\")\n",
    "# C:\\Users\\daban\\Documents\\schoolfiles\\img\\PXL_20241110_020044637.jpg\n",
    "img = cv2.imread(\"img/Pepper.bmp\", cv2.IMREAD_COLOR)\n",
    "results = model.predict(img, conf=0.5)\n",
    "result = results[0]\n",
    "plot = result.plot()\n",
    "cv2.imshow(\"YOLO\", plot)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 1 skateboard, 88.8ms\n",
      "Speed: 3.0ms preprocess, 88.8ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "<class 'ultralytics.engine.results.Results'>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(result))\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mnamedWindow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mWINDOW_NORMAL)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     15\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "File \u001b[1;32mc:\\Users\\daban\\Documents\\schoolfiles\\.env\\Lib\\site-packages\\ultralytics\\utils\\patches.py:56\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    Displays an image in the specified window.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        mat (np.ndarray): Image to be shown.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     \u001b[43m_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43municode_escape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "# 06\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"cascade/yolov8n-seg.pt\")\n",
    "img = cv2.imread(\"img/bus.jpg\")\n",
    "results = model.predict(img)\n",
    "result = results[0]\n",
    "\n",
    "mask = result.masks[0]\n",
    "print(type(result))\n",
    "\n",
    "cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"result\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  'source' is missing. Using 'source=C:\\Users\\daban\\Documents\\schoolfiles\\.env\\Lib\\site-packages\\ultralytics\\assets'.\n",
      "\n",
      "image 1/2 C:\\Users\\daban\\Documents\\schoolfiles\\.env\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 81.2ms\n",
      "image 2/2 C:\\Users\\daban\\Documents\\schoolfiles\\.env\\Lib\\site-packages\\ultralytics\\assets\\zidane.jpg: 384x640 2 persons, 1 tie, 72.2ms\n",
      "Speed: 2.5ms preprocess, 76.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "m = YOLO(\"cascade/yolov8n-seg.pt\")  \n",
    "res = m.predict()  \n",
    "\n",
    "# Iterate detection results \n",
    "for r in res:\n",
    "    img = np.copy(r.orig_img)\n",
    "    img_name = Path(r.path).stem\n",
    "\n",
    "    # Iterate each object contour \n",
    "    for ci, c in enumerate(r):\n",
    "        label = c.names[c.boxes.cls.tolist().pop()]\n",
    "\n",
    "        b_mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "        # Create contour mask \n",
    "        contour = c.masks.xy.pop().astype(np.int32).reshape(-1, 1, 2)\n",
    "        _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "        # Choose one:\n",
    "\n",
    "        # OPTION-1: Isolate object with black background\n",
    "        mask3ch = cv2.cvtColor(b_mask, cv2.COLOR_GRAY2BGR)\n",
    "        isolated = cv2.bitwise_and(mask3ch, img)\n",
    "\n",
    "        # OPTION-2: Isolate object with transparent background (when saved as PNG)\n",
    "        isolated = np.dstack([img, b_mask])\n",
    "\n",
    "        # OPTIONAL: detection crop (from either OPT1 or OPT2)\n",
    "        x1, y1, x2, y2 = c.boxes.xyxy.cpu().numpy().squeeze().astype(np.int32)\n",
    "        iso_crop = isolated[y1:y2, x1:x2]\n",
    "\n",
    "        # TODO your actions go here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
