{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オブジェクト除去\n",
    "左の鸚鵡を消す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/Parrots.bmp\")\n",
    "h, w ,c = img.shape\n",
    "mask = np.zeros((h, w, c), np.uint8)\n",
    "cv2.imshow(\"Original\", img)\n",
    "\n",
    "cv2.rectangle(mask, (90, 0), (0, 480), (255, 255, 255), -1)\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "dst = cv2.inpaint(img, mask, 1, cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"Inpaint\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像修復\n",
    "画像に入った白線を消す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/Pepper-inpaint.jpg\")\n",
    "mask = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(mask, 220, 255, cv2.THRESH_BINARY)\n",
    "dst = cv2.inpaint(img, mask, 1, cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Inpaint\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コーナー検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/milkdrop.bmp\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "dst = img.copy()\n",
    "corners = cv2.goodFeaturesToTrack(img_gray, 70, 0.08, 10)\n",
    "for i in corners:\n",
    "    x = int(i[0][0])\n",
    "    y = int(i[0][1])\n",
    "    cv2.circle(dst, (x, y), 3, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Corners\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AKAZE\n",
    "元画像・傾けた画像の特徴点を検出し、マッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"img/Parrots.bmp\", 0)\n",
    "h1, w1 = img1.shape\n",
    "center = (int(w1/2), int(h1/2))\n",
    "trans = cv2.getRotationMatrix2D(center, 30.0, 1.0)\n",
    "img2 = cv2.warpAffine(img1, trans, (w1, h1))\n",
    "h2, w2 = img2.shape\n",
    "detertor = cv2.AKAZE_create()\n",
    "kpts1, desc1 = detertor.detectAndCompute(img1, None)\n",
    "kpts2, desc2 = detertor.detectAndCompute(img2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc1)\n",
    "dst1 = np.zeros((h1, w1+w1, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img1, kpts1, matches, dst1)\n",
    "cv2.imshow(\"Matches\", dst1)\n",
    "\n",
    "matches = matcher.match(desc1, desc2)\n",
    "dst2 = np.zeros((max(h1, h2), w1+w2, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img2, kpts2, matches, dst2)\n",
    "cv2.imshow(\"Matches\", dst2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"img/Parrots.bmp\", 0)\n",
    "h1, w1 = img1.shape\n",
    "center = (int(w1/2), int(h1/2))\n",
    "trans = cv2.getRotationMatrix2D(center, 30.0, 1.0)\n",
    "img2 = cv2.warpAffine(img1, trans, (w1, h1))\n",
    "h2, w2 = img2.shape\n",
    "detertor = cv2.ORB_create()\n",
    "kpts1, desc1 = detertor.detectAndCompute(img1, None)\n",
    "kpts2, desc2 = detertor.detectAndCompute(img2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc1)\n",
    "dst1 = np.zeros((h1, w1+w1, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img1, kpts1, matches, dst1)\n",
    "cv2.imshow(\"Matches\", dst1)\n",
    "\n",
    "matches = matcher.match(desc1, desc2)\n",
    "dst2 = np.zeros((max(h1, h2), w1+w2, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img2, kpts2, matches, dst2)\n",
    "cv2.imshow(\"Matches\", dst2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB - 上位50点をマッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"img/Parrots.bmp\", 0)\n",
    "h1, w1 = img1.shape\n",
    "center = (int(w1/2), int(h1/2))\n",
    "trans = cv2.getRotationMatrix2D(center, 30.0, 1.0)\n",
    "img2 = cv2.warpAffine(img1, trans, (w1, h1))\n",
    "h2, w2 = img2.shape\n",
    "detertor = cv2.ORB_create()\n",
    "kpts1, desc1 = detertor.detectAndCompute(img1, None)\n",
    "kpts2, desc2 = detertor.detectAndCompute(img2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "dst = np.zeros((max(h1, h2), w1+w2, 3), np.uint8)\n",
    "cv2.drawMatches(img1, kpts1, img2, kpts2, matches[:10], dst)\n",
    "cv2.imshow(\"Matches\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テンプレートマッチング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = cv2.imread(\"img/Parrots.bmp\")\n",
    "cv2.imwrite(\"img/template.jpg\", tmp[100:200, 100:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テンプレートマッチング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/Parrots.bmp\", 0)\n",
    "tmp = cv2.imread(\"img/template.jpg\", 0)\n",
    "h, w = tmp.shape\n",
    "res = cv2.matchTemplate(img, tmp, cv2.TM_SQDIFF)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "top_left = min_loc \n",
    "bottom_right = (top_left[0]+w, top_left[1]+h)\n",
    "cv2.rectangle(img, top_left, bottom_right, 255, 2)\n",
    "cv2.imshow(\"Match\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスケード分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 顔検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/Lenna.bmp\")\n",
    "cascade = cv2.CascadeClassifier(\"cascade/haarcascade_frontalface_alt.xml\")\n",
    "face = cascade.detectMultiScale(img)\n",
    "\n",
    "if len(face) > 0:\n",
    "    for x, y, w, h in face:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "else:\n",
    "    print(\"No face detected\")\n",
    "\n",
    "cv2.imshow(\"Face\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目の検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/Lenna.bmp\")\n",
    "cascade = cv2.CascadeClassifier(\"cascade/haarcascade_eye.xml\")\n",
    "face = cascade.detectMultiScale(img)\n",
    "\n",
    "if len(face) > 0:\n",
    "    for x, y, w, h in face:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "else:\n",
    "    print(\"No face detected\")\n",
    "\n",
    "cv2.imshow(\"Face\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x224 cowboy_hat 0.44, sombrero 0.39, brassiere 0.09, mask 0.01, bonnet 0.01, 16.9ms\n",
      "Speed: 2.1ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"cascade/yolov8n-cls.pt\")\n",
    "# C:\\Users\\daban\\Documents\\schoolfiles\\img\\PXL_20241110_020044637.jpg\n",
    "img = cv2.imread(\"img/Lenna.bmp\", cv2.IMREAD_COLOR)\n",
    "results = model.predict(img, conf=0.5)\n",
    "result = results[0]\n",
    "plot = result.plot()\n",
    "cv2.imshow(\"YOLO\", plot)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セグメンテーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 1 skateboard, 95.3ms\n",
      "Speed: 2.9ms preprocess, 95.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mc:\\Users\\daban\\Documents\\schoolfiles\\runs\\segment\\predict16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"cascade/yolov8n-seg.pt\")\n",
    "img = cv2.imread(\"img/bus.jpg\")\n",
    "results = model.predict(img, save=True, show_boxes = False)\n",
    "result = results[0]\n",
    "plot = result.plot()\n",
    "cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"result\", plot)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 骨格推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt to 'cascade\\yolov8n-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.52M/6.52M [00:00<00:00, 14.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 74.8ms\n",
      "Speed: 3.1ms preprocess, 74.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"cascade/yolov8n-pose.pt\")\n",
    "img = cv2.imread(\"img/bus.jpg\")\n",
    "results = model.predict(img)\n",
    "result = results[0]\n",
    "plot = result.plot()\n",
    "cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"result\", plot)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
